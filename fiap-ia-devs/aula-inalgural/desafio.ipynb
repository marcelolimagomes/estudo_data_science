{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# navigation and read files\n",
    "import os\n",
    "\n",
    "# Read HDF5 binary data format: convenient for large data storage\n",
    "import h5py\n",
    "\n",
    "# Read and display images\n",
    "import matplotlib.pyplot as plt\n",
    "import imageio\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "# from tensorflow import keras\n",
    "\n",
    "# DL dependancies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of images\n",
    "PATH_TO_DATA = './'\n",
    "CSV_FILES = ['letters.csv', 'letters2.csv', 'letters3.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(CSV_FILE):\n",
    "    data = pd.read_csv(PATH_TO_DATA + CSV_FILE)\n",
    "    # Create path extention for corresponding folders that contains images\n",
    "    data['source'] = CSV_FILE[:-4] + '/'\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = import_data(CSV_FILES[0])\n",
    "data2 = import_data(CSV_FILES[1])\n",
    "data3 = import_data(CSV_FILES[2])\n",
    "data = pd.concat([data1, data2, data3], ignore_index=True)\n",
    "\n",
    "# I won't use these data anymore\n",
    "del (data1, data2, data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "data = shuffle(data, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all labels in one string\n",
    "letters = ''\n",
    "for letter in data.letter.unique():\n",
    "    letters += letter\n",
    "\n",
    "# Which letter is written on each image\n",
    "labels = data.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_letters(label):\n",
    "    '''\n",
    "    One hot encoding for the target label\n",
    "    '''\n",
    "    resu = np.zeros(len(letters))\n",
    "    index = letters.index(label)\n",
    "    resu[index] = 1\n",
    "    return resu\n",
    "\n",
    "\n",
    "def ohe_backgrounds(label):\n",
    "    '''\n",
    "    One hot encoding for background column\n",
    "    '''\n",
    "    resu = np.zeros(len(data.background.unique()))\n",
    "    resu[label] = 1\n",
    "    return resu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['encoded_letter'] = data['letter'].apply(lambda x: ohe_letters(x))\n",
    "data['encoded_background'] = data['background'].apply(lambda x: ohe_backgrounds(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all png images into one numpy array\n",
    "images = []\n",
    "# Will be the target\n",
    "encoded_labels = []\n",
    "\n",
    "backgrounds = []\n",
    "encoded_backgrounds = []\n",
    "\n",
    "# I want to be sure that every image is consitent\n",
    "for i, row in data.iterrows():\n",
    "    img_name = row['file']\n",
    "    numpy_image = cv2.imread(os.path.join(PATH_TO_DATA + row['source'], img_name))\n",
    "    if numpy_image.shape == (32, 32, 3):\n",
    "        images.append(numpy_image)\n",
    "        encoded_labels.append(row['encoded_letter'])\n",
    "        backgrounds.append(row['background'])\n",
    "        encoded_backgrounds.append(row['encoded_background'])\n",
    "\n",
    "# Normalize array of images\n",
    "images = np.array(images) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(images_list, list_of_labels=np.arange(9)):\n",
    "\n",
    "    # plot first few images\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for index in list_of_labels:\n",
    "\n",
    "        # Get corresponding label\n",
    "        ohe_label = encoded_labels[index]\n",
    "        index_letter = list(ohe_label).index(1)\n",
    "        associated_letter = letters[index_letter]\n",
    "\n",
    "        # Get background\n",
    "        associated_background = backgrounds[index]\n",
    "\n",
    "        # define subplot\n",
    "        plt.subplot(330 + 1 + index)\n",
    "        plt.title('Label: %s \\n' % associated_letter +\n",
    "                  'Background: %s\\n' % associated_background,\n",
    "                  fontsize=18)\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(images[index])\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.001)  # the bottom of the subplots of the figure\n",
    "    plt.subplots_adjust(top=0.99)\n",
    "    # show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_image(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X_data and target\n",
    "X = np.array(images.copy())\n",
    "y = np.array(encoded_labels.copy())\n",
    "\n",
    "# Stratified train_test split on labels\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y,\n",
    "                                                  test_size=.2,\n",
    "                                                  stratify=y,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image dimensions\n",
    "IMG_ROWS = 32\n",
    "IMG_COLS = 32\n",
    "# 3 stands for RGB images, 1 if greyscaled images\n",
    "INPUT_SHAPE = (IMG_ROWS, IMG_COLS, 3)\n",
    "\n",
    "# Number of classes to consider\n",
    "NUM_CLASSES = len(letters)\n",
    "# Group of training samples\n",
    "BATCH_SIZE = 64\n",
    "# Number of complete presentations of the dataset to be learned\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3_categorical_accuracy(y_true, y_pred):\n",
    "    return top_k_categorical_accuracy(y_true, y_pred, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_model(activation='softmax',\n",
    "              loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy', top_3_categorical_accuracy]):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     input_shape=INPUT_SHAPE))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(128, (4, 4), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(NUM_CLASSES, activation=activation))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init CNN model\n",
    "cnn_model = CNN_model()\n",
    "\n",
    "# Save weights only for best model\n",
    "checkpointer = ModelCheckpoint(filepath='weights.best.letters.hdf5',\n",
    "                               verbose=2,\n",
    "                               save_best_only=True)\n",
    "\n",
    "# Reduce learning rate when a metric has stopped improving\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                 patience=10,\n",
    "                                 verbose=2,\n",
    "                                 factor=.75)\n",
    "\n",
    "# If score doesn't improve during patience=20 epochs, stop learning\n",
    "estopping = EarlyStopping(monitor='val_loss',\n",
    "                          patience=20,\n",
    "                          verbose=2)\n",
    "\n",
    "# Training\n",
    "history = cnn_model.fit(X_train, y_train,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        epochs=EPOCHS,\n",
    "                        verbose=1,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        callbacks=[checkpointer, lr_reduction, estopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(model_history):\n",
    "\n",
    "    plt.figure(figsize=(20, 15))\n",
    "\n",
    "    plt.subplot(221)\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(model_history.history['top_3_categorical_accuracy'])\n",
    "    plt.plot(model_history.history['val_top_3_categorical_accuracy'])\n",
    "    plt.title('top_3_categorical_accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(222)\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(model_history.history['accuracy'])\n",
    "    plt.plot(model_history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(223)\n",
    "    # summarize history for loss\n",
    "    plt.plot(model_history.history['loss'])\n",
    "    plt.plot(model_history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(224)\n",
    "    # summarize history for lr\n",
    "    plt.plot(model_history.history['lr'])\n",
    "    plt.title('learning rate')\n",
    "    plt.ylabel('lr')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model with the best validation accuracy\n",
    "cnn_model.load_weights(\"weights.best.letters.hdf5\")\n",
    "cnn_model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path_filename):\n",
    "    # load the image\n",
    "    img = load_img(path_filename, target_size=(32, 32))\n",
    "    # convert to array\n",
    "    img = img_to_array(img)\n",
    "    # reshape into a single sample with 1 channel\n",
    "    img = img.reshape(1, 32, 32, 3)\n",
    "    # prepare pixel data\n",
    "    img = img.astype('float32')\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_label(path_filename, dataframe, column_to_get):\n",
    "    filename = os.path.basename(os.path.normpath(path_filename))\n",
    "    index_row = data[data['file'] == filename].index[0]\n",
    "    return data.loc[index_row, column_to_get]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_image(PATH_TO_DATA + 'letters3/01_235.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the class\n",
    "# a_letter = cnn_model.predict_classes(img) # TensorFlow 2.5\n",
    "\n",
    "predict_x = cnn_model.predict(img)\n",
    "classes_x = np.argmax(predict_x, axis=1)\n",
    "\n",
    "plt.imshow(img[0])\n",
    "print('predicted:', letters[classes_x[0]])\n",
    "print('true label:', get_true_label(PATH_TO_DATA + 'letters3/01_235.png', data, 'letter'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_random_images(number_of_images_to_load=9):\n",
    "    images = []\n",
    "    true_labels = []\n",
    "    true_backgrounds = []\n",
    "\n",
    "    which_folder = [random.randint(1, 3) for _ in range(number_of_images_to_load)]\n",
    "    for index_folder in which_folder:\n",
    "        if index_folder == 1:\n",
    "            path = PATH_TO_DATA + 'letters/'\n",
    "        else:\n",
    "            path = PATH_TO_DATA + 'letters' + str(index_folder) + '/'\n",
    "        nb_files = len(os.listdir(path))\n",
    "\n",
    "        index_image = random.randint(0, len(os.listdir(path)))\n",
    "\n",
    "        image = load_image(path + os.listdir(path)[index_image])\n",
    "        label = get_true_label(path + os.listdir(path)[index_image], data, 'letter')\n",
    "        background = get_true_label(path + os.listdir(path)[index_image], data, 'background')\n",
    "\n",
    "        images.append(image)\n",
    "        true_labels.append(label)\n",
    "        true_backgrounds.append(background)\n",
    "\n",
    "    return images, true_labels, true_backgrounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classes_predictions(images_list_to_classify, true_labels, model):\n",
    "\n",
    "    # plot first few images\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    for index, image in enumerate(images_list_to_classify):\n",
    "\n",
    "        # a_letter = model.predict_classes(image)\n",
    "        predict_x = cnn_model.predict(img)\n",
    "        a_letter = np.argmax(predict_x, axis=1)\n",
    "\n",
    "        associated_letter = letters[a_letter[0]]\n",
    "\n",
    "        # define subplot\n",
    "        plt.subplot(330 + 1 + index)\n",
    "        plt.title('Predicted Label: %s \\n' % associated_letter +\n",
    "                  'True Label: %s\\n' % true_labels[index],\n",
    "                  fontsize=18)\n",
    "        # plot raw pixel data\n",
    "        plt.imshow(image[0])\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.001)  # the bottom of the subplots of the figure\n",
    "    plt.subplots_adjust(top=0.99)\n",
    "\n",
    "    # show the figure\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, true_labels, true_backgrounds = load_random_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_predictions(test_images, true_labels, cnn_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
