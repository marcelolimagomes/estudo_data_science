{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0vyizWCxt91x"
   },
   "source": [
    "# Aula 1 - Criando um gerador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4cCz4y4JuCov"
   },
   "source": [
    "## Vídeo 1.2 - Carregando o fmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zx9k7PnGt2AY"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tcKJA4fluAfT"
   },
   "outputs": [],
   "source": [
    "# Carregar o dataset Fashion MNIST\n",
    "(train_images, train_labels), _ = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Normalizar as imagens para o intervalo [-1, 1]\n",
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5  # Normalizar para [-1, 1]\n",
    "\n",
    "# Definir o batch size e preparar o dataset para treinamento\n",
    "batch_size = 256\n",
    "\n",
    "# Criar o dataset de treino\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train_images).shuffle(60000).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir algumas imagens de exemplo\n",
    "num_images_to_show = 10\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(num_images_to_show):\n",
    "    plt.subplot(1, num_images_to_show, i + 1)\n",
    "    plt.imshow(train_images[i].reshape(28, 28), cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jShPRfUdKZd"
   },
   "source": [
    "## Vídeo 1.3 - Estruturando um gerador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clxKbCZb0Lia"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLwsCwkKepwg"
   },
   "outputs": [],
   "source": [
    "def constroi_gerador():\n",
    "    modelo = Sequential()\n",
    "\n",
    "    modelo.add(layers.Input(shape=(100,)))\n",
    "    modelo.add(layers.Dense(7*7*256, use_bias=False))\n",
    "    modelo.add(layers.BatchNormalization())\n",
    "    modelo.add(layers.LeakyReLU())\n",
    "\n",
    "    modelo.add(layers.Reshape((7, 7, 256)))\n",
    "    modelo.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    modelo.add(layers.BatchNormalization())\n",
    "    modelo.add(layers.LeakyReLU())\n",
    "\n",
    "    modelo.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    modelo.add(layers.BatchNormalization())\n",
    "    modelo.add(layers.LeakyReLU())\n",
    "\n",
    "    modelo.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "\n",
    "    return modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5ClnLX-e0lb"
   },
   "source": [
    "## Vídeo 1.4 - Gerando uma imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ulo-HN3RevHf"
   },
   "outputs": [],
   "source": [
    "# Criação do gerador\n",
    "gerador = constroi_gerador()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sunt5us_e6d0"
   },
   "outputs": [],
   "source": [
    "# Gerar Vetor de Ruído\n",
    "dimensao_ruido = 100\n",
    "ruido = tf.random.normal([1, dimensao_ruido])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgG6cpNSe7ol"
   },
   "outputs": [],
   "source": [
    "# Gerar imagem a partir do vetor de ruído\n",
    "imagem_gerada = gerador(ruido, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "id": "L7dztwv6e9gR",
    "outputId": "e2f42702-b20f-4e9c-da1e-3f94e79589df"
   },
   "outputs": [],
   "source": [
    "# Visualizar a imagem gerada\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow((imagem_gerada[0] * 127.5 + 127.5).numpy())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIotW2irgVbX"
   },
   "source": [
    "# Aula 2 - Implementando um discriminador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fbv8H7-gd1i"
   },
   "source": [
    "## Vídeo 2.1 - Criando a função do discriminador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYxcmbDVe_kk"
   },
   "outputs": [],
   "source": [
    "def constroi_discriminador():\n",
    "    modelo = Sequential()\n",
    "\n",
    "    modelo.add(layers.Input(shape=(28, 28, 1)))\n",
    "    modelo.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same'))\n",
    "    modelo.add(layers.LeakyReLU())\n",
    "    modelo.add(layers.Dropout(0.3))\n",
    "\n",
    "    modelo.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    modelo.add(layers.LeakyReLU())\n",
    "    modelo.add(layers.Dropout(0.3))\n",
    "\n",
    "    # Corrigir a dimensão da Flatten para compatibilizar com a Dense\n",
    "    modelo.add(layers.Flatten())\n",
    "    modelo.add(layers.Dense(1))\n",
    "\n",
    "    return modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6tnGgaBlidq",
    "outputId": "1a37dad9-3afa-486d-dfa6-cfb62912e9bd"
   },
   "outputs": [],
   "source": [
    "discriminador = constroi_discriminador()\n",
    "decisao = discriminador(imagem_gerada)\n",
    "print(decisao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovrpRt8tpcSn"
   },
   "source": [
    "## Vídeo 2.2 - Definindo as funções de custo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CsSJXORBoda-"
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdzQEQDIpjrA"
   },
   "outputs": [],
   "source": [
    "def custo_discriminador(real_output, fake_output):\n",
    "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    total_loss = real_loss + fake_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jz_92tEipw9s"
   },
   "outputs": [],
   "source": [
    "def custo_gerador(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9qaoRwv4p4Y7"
   },
   "outputs": [],
   "source": [
    "otimizador_gerador = tf.keras.optimizers.Adam(1e-4)\n",
    "otimizador_discriminador = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6-G8MGywqdIA"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G2CJ9rWRqpaE"
   },
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=otimizador_gerador,\n",
    "                                 discriminator_optimizer=otimizador_discriminador,\n",
    "                                 generator=gerador,\n",
    "                                 discriminator=discriminador)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_RDNecVsbaV"
   },
   "source": [
    "## Vídeo 2.3 - Definindo um loop de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nsvRuLjmsJTS"
   },
   "outputs": [],
   "source": [
    "epocas = 50\n",
    "dimensao_ruido = 100\n",
    "numero_exemplos_treinamento = 16\n",
    "\n",
    "#Vetor de ruido para gerar imagens\n",
    "seed = tf.random.normal([numero_exemplos_treinamento, dimensao_ruido])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S7FonarCu4S2"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def passo_treino(images):\n",
    "    ruido = tf.random.normal([batch_size, dimensao_ruido])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_images = gerador(ruido, training=True)\n",
    "\n",
    "        real_output = discriminador(images, training=True)\n",
    "        fake_output = discriminador(generated_images, training=True)\n",
    "\n",
    "        gen_loss = custo_gerador(fake_output)\n",
    "        disc_loss = custo_discriminador(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, gerador.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminador.trainable_variables)\n",
    "\n",
    "    otimizador_gerador.apply_gradients(zip(gradients_of_generator, gerador.trainable_variables))\n",
    "    otimizador_discriminador.apply_gradients(zip(gradients_of_discriminator, discriminador.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tz9GLgBNvqiQ"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BD6-BoQWxU4S"
   },
   "outputs": [],
   "source": [
    "def treino(dataset, epocas):\n",
    "    for epoca in range(epocas):\n",
    "        start = time.time()\n",
    "\n",
    "        for image_batch in dataset:\n",
    "           passo_treino(image_batch)\n",
    "\n",
    "        # Produz as imagens para gerar um gif\n",
    "        clear_output(wait=True)\n",
    "        gera_e_salva_imagens(gerador,\n",
    "                                 epoca + 1,\n",
    "                                 seed)\n",
    "\n",
    "        # Salva o modelo a cada 15 épocas\n",
    "        if (epoca + 1) % 15 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "\n",
    "        print('Tempo por época {} é {} s'.format(epoca + 1, time.time()-start))\n",
    "\n",
    "    # Gera após a época final\n",
    "    clear_output(wait=True)\n",
    "    gera_e_salva_imagens(gerador,\n",
    "                                 epoca + 1,\n",
    "                                 seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ygxkc9U-yphv"
   },
   "outputs": [],
   "source": [
    "def gera_e_salva_imagens(modelo, epoca, entrada):\n",
    "  # Observe que `training` está definido como False.\n",
    "  # Isso é para que todas as camadas sejam executadas no modo de inferência (batchnorm).\n",
    "  previsao = modelo(entrada, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4, 4))\n",
    "\n",
    "  for i in range(previsao.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(previsao[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoca))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eU0xY-LdzRxL"
   },
   "source": [
    "## Vídeo 2.4 - Aplicando o treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 362
    },
    "id": "3tY121dmzI9P",
    "outputId": "5a19bead-2d81-420f-9fa6-3fdb62c28b3d"
   },
   "outputs": [],
   "source": [
    "treino(train_ds, epocas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cZp9d8WkzntF"
   },
   "outputs": [],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gerador.save('modelo_gerador.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "gerador_carregado = load_model('modelo_gerador.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar um novo vetor de ruído\n",
    "new_noise = tf.random.normal([1, dimensao_ruido])\n",
    "\n",
    "# Gerar uma nova imagem usando o modelo carregado\n",
    "new_generated_image = gerador_carregado(new_noise, training=False)\n",
    "\n",
    "# Visualizar a nova imagem gerada\n",
    "plt.imshow((new_generated_image[0] * 127.5 + 127.5).numpy())\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 3 - Construindo um difusor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vídeo 3.1 - Adicionando de ruído"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import layers\n",
    "from tqdm.auto import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o dataset Fashion MNIST\n",
    "(X_treino, y_treino), (X_teste, y_teste) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "# Normalizando as imagens para o intervalo [-1, 1]\n",
    "X_treino = (X_treino / 127.5) - 1.0\n",
    "\n",
    "# Adicionando um canal extra para as imagens de 28x28\n",
    "X_treino = np.expand_dims(X_treino, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 28     # Tamanho das imagens de entrada, Fashion MNIST é 28x28\n",
    "BATCH_SIZE = 128  # Tamanho do lote para treinamento\n",
    "timesteps = 16    # Quantidade de passos para uma imagem ruidosa se tornar clara\n",
    "time_bar = 1 - np.linspace(0, 1.0, timesteps + 1) # linspace para timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvtImg(img):\n",
    "    img = img - img.min()\n",
    "    img = (img / img.max())\n",
    "    return img.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_examples(x):\n",
    "    num_images = x.shape[0]\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    for i in range(min(25, num_images)):  # Mostra no máximo 25 imagens\n",
    "        plt.subplot(5, 5, i+1)\n",
    "        img = cvtImg(x[i])\n",
    "        plt.imshow(img.squeeze(), cmap='gray')  # Exibe como imagem em escala de cinza\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_examples(X_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_noise(x, t):\n",
    "    a = time_bar[t]      # imagem no tempo t\n",
    "    b = time_bar[t + 1]  # imagem em t + 1\n",
    "\n",
    "    ruido = np.random.normal(size=x.shape)  # Gera máscara de ruído\n",
    "    a = a.reshape((-1, 1, 1, 1))\n",
    "    b = b.reshape((-1, 1, 1, 1))\n",
    "    img_a = x * (1 - a) + ruido * a\n",
    "    img_b = x * (1 - b) + ruido * b\n",
    "    return img_a, img_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ts(num):\n",
    "    return np.random.randint(0, timesteps, size=num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gera exemplos de treino\n",
    "t = generate_ts(3)  # Gera timesteps para 25 exemplos\n",
    "a, b = forward_noise(X_treino[:3], t)\n",
    "show_examples(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vídeo 3.2 - Implementando uma U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(x):\n",
    "    x = layers.Conv2D(128, kernel_size=3, padding='same')(x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    # Ajuste na entrada para Fashion MNIST\n",
    "    x = x_input = layers.Input(shape=(28, 28, 1), name='x_input')\n",
    "\n",
    "    x_ts = x_ts_input = layers.Input(shape=(1,), name='x_ts_input')\n",
    "    x_ts = layers.Dense(192)(x_ts)\n",
    "    x_ts = layers.LayerNormalization()(x_ts)\n",
    "    x_ts = layers.Activation('relu')(x_ts)\n",
    "\n",
    "    # ----- left ( down ) -----\n",
    "    x = x28 = block(x)  # 28x28 -> 28x28\n",
    "    x = layers.MaxPool2D(2, padding='same')(x)  # 28x28 -> 14x14\n",
    "\n",
    "    x = x14 = block(x)  # 14x14 -> 14x14\n",
    "    x = layers.MaxPool2D(2, padding='same')(x)  # 14x14 -> 7x7\n",
    "\n",
    "    x = x7 = block(x)  # 7x7 -> 7x7\n",
    "    x = layers.MaxPool2D(2, padding='same')(x)  # 7x7 -> 4x4\n",
    "\n",
    "    x = x4 = block(x)  # 4x4 -> 4x4\n",
    "\n",
    "    # ----- MLP -----\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Concatenate()([x, x_ts])\n",
    "    x = layers.Dense(128)(x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Dense(4 * 4 * 32)(x)\n",
    "    x = layers.LayerNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "    x = layers.Reshape((4, 4, 32))(x)\n",
    "\n",
    "    # ----- right ( up ) -----\n",
    "    x = layers.Concatenate()([x, x4])\n",
    "    x = block(x)\n",
    "    x = layers.Conv2DTranspose(128, kernel_size=3, strides=2, padding='same')(x)  # 4x4 -> 8x8\n",
    "\n",
    "    # Ajuste para 7x7\n",
    "    x = layers.Cropping2D(((0, 1), (0, 1)))(x)  # 8x8 -> 7x7\n",
    "\n",
    "    x = layers.Concatenate()([x, x7])\n",
    "    x = block(x)\n",
    "    x = layers.Conv2DTranspose(128, kernel_size=3, strides=2, padding='same')(x)  # 7x7 -> 14x14\n",
    "\n",
    "    x = layers.Concatenate()([x, x14])\n",
    "    x = block(x)\n",
    "    x = layers.Conv2DTranspose(128, kernel_size=3, strides=2, padding='same')(x)  # 14x14 -> 28x28\n",
    "\n",
    "    x = layers.Concatenate()([x, x28])\n",
    "    x = block(x)\n",
    "\n",
    "    # ----- output -----\n",
    "    x = layers.Conv2D(1, kernel_size=1, padding='same')(x)\n",
    "    model = tf.keras.models.Model([x_input, x_ts_input], x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.MeanAbsoluteError(), optimizer=tf.keras.optimizers.Adam(learning_rate=0.0008))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vídeo 3.3 - Criando funções de previsão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, timesteps=50, batch_size=32):\n",
    "    # Inicialize com ruído gaussiano\n",
    "    x = np.random.normal(size=(batch_size, 28, 28, 1))\n",
    "\n",
    "    for i in trange(timesteps):\n",
    "        t = np.full((batch_size, 1), i)  # Tempo como um vetor coluna\n",
    "        x = model.predict([x, t], verbose=0)\n",
    "\n",
    "    # Normalize as imagens para o intervalo [0, 1]\n",
    "    x = (x - x.min()) / (x.max() - x.min())\n",
    "\n",
    "    show_examples(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_step(model, timesteps=50, num_samples=8):\n",
    "    xs = []\n",
    "    x = np.random.normal(size=(num_samples, 28, 28, 1))  # Ajustado para Fashion MNIST\n",
    "\n",
    "    for i in trange(timesteps):\n",
    "        t = np.full((num_samples, 1), i)  # Tempo como vetor coluna\n",
    "        x = model.predict([x, t], verbose=0)\n",
    "        if i % 5 == 0:  # Salva a cada 5 passos para reduzir o número de imagens\n",
    "            xs.append(x[0])\n",
    "\n",
    "    # Normaliza as imagens para o intervalo [0, 1]\n",
    "    xs = [(x - x.min()) / (x.max() - x.min()) for x in xs]\n",
    "\n",
    "    plt.figure(figsize=(20, 3))\n",
    "    for i, img in enumerate(xs):\n",
    "        plt.subplot(1, len(xs), i+1)\n",
    "        plt.imshow(cvtImg(img), cmap='gray')\n",
    "        plt.title(f'Step {i*5}')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vídeo 3.4 - Treinando a U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one(x_img):\n",
    "    x_ts = generate_ts(len(x_img))\n",
    "    x_a, x_b = forward_noise(x_img, x_ts)\n",
    "    loss = model.train_on_batch([x_a, x_ts], x_b)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(R=50):\n",
    "    bar = trange(R)\n",
    "    total = 100\n",
    "    for i in bar:\n",
    "        for j in range(total):\n",
    "            x_img = X_treino[np.random.randint(len(X_treino), size=BATCH_SIZE)]\n",
    "            loss = train_one(x_img)\n",
    "            pg = (j / total) * 100\n",
    "            if j % 5 == 0:\n",
    "                bar.set_description(f'loss: {loss:.5f}, p: {pg:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_step(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 4 - Usando o Stable Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vídeo 4.1 - Gerando com o Stable Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip uninstall keras keras-core keras-cv tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install tensorflow==2.15.1 keras==2.15.0 keras-core==0.1.7 keras-cv==0.9.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import keras_cv\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = keras_cv.models.StableDiffusion(img_width=512, img_height=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens = modelo.text_to_image(\n",
    "  \"Humanoid dog playing guitar \",\n",
    "  batch_size=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(imagens):\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(len(imagens)):\n",
    "        ax = plt.subplot(1, len(imagens), i + 1)\n",
    "        plt.imshow(imagens[i])\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(imagens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/generative/generate_images_with_stable_diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vídeo 4.2 - Melhorando a precisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens = modelo.text_to_image(\n",
    "    \"Humanoid cat wearing golden jeans, dark fantasy art, \"\n",
    "    \"high quality, highly detailed, elegant, sharp focus, \"\n",
    "    \"concept art, character concepts, digital painting, mystery, adventure\",\n",
    "    batch_size=3,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(imagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = keras_cv.models.StableDiffusion(img_width=512, img_height=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens = modelo.text_to_image(\n",
    "    \"Panda wearing a blue hat, dark fantasy art, \"\n",
    "    \"high quality, highly detailed, elegant, sharp focus, \"\n",
    "    \"concept art, character concepts, digital painting, mystery, adventure\",\n",
    "    batch_size=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(imagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.mixed_precision.set_global_policy(\"float32\")\n",
    "modelo = keras_cv.models.StableDiffusion(img_width=512, img_height=512,jit_compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagens = modelo.text_to_image(\n",
    "    \"Cat wearing a furry hat, dark fantasy art, \"\n",
    "    \"high quality, highly detailed, elegant, sharp focus, \"\n",
    "    \"concept art, character concepts, digital painting, mystery, adventure\",\n",
    "    batch_size=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images(imagens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aula 5 - Gerando animações com o Stable Difusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vídeo 5.1 - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_cv\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.mixed_precision.set_global_policy(\"mixed_float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Stable Diffusion model\n",
    "model = keras_cv.models.StableDiffusion(jit_compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = \"Panda wearing a blue hat, dark fantasy art, \"\n",
    "prompt_2 = \"Cat wearing a blue hat, dark fantasy art, \"\n",
    "interpolation_steps = 5\n",
    "\n",
    "encoding_1 = tf.squeeze(model.encode_text(prompt_1))\n",
    "encoding_2 = tf.squeeze(model.encode_text(prompt_2))\n",
    "\n",
    "interpolated_encodings = tf.linspace(encoding_1, encoding_2, interpolation_steps)\n",
    "\n",
    "# Show the size of the latent manifold\n",
    "print(f\"Encoding shape: {encoding_1.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 12345\n",
    "noise = tf.random.normal((512 // 8, 512 // 8, 4), seed=seed)\n",
    "\n",
    "images = model.generate_image(\n",
    "    interpolated_encodings,\n",
    "    batch_size=interpolation_steps,\n",
    "    diffusion_noise=noise,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_as_gif(filename, images, frames_per_second=10, rubber_band=False):\n",
    "    if rubber_band:\n",
    "        images += images[2:-1][::-1]\n",
    "    images[0].save(\n",
    "        filename,\n",
    "        save_all=True,\n",
    "        append_images=images[1:],\n",
    "        duration=1000 // frames_per_second,\n",
    "        loop=0,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_as_gif(\n",
    "    \"panda-cat.gif\",\n",
    "    [Image.fromarray(img) for img in images],\n",
    "    frames_per_second=2,\n",
    "    rubber_band=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image as IImage\n",
    "IImage(\"panda-cat.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vídeo 5.2 - Interpolação manual dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolation_steps = 150\n",
    "batch_size = 3\n",
    "batches = interpolation_steps // batch_size\n",
    "\n",
    "interpolated_encodings = tf.linspace(encoding_1, encoding_2, interpolation_steps)\n",
    "batched_encodings = tf.split(interpolated_encodings, batches)\n",
    "\n",
    "images = []\n",
    "for batch in range(batches):\n",
    "    images += [\n",
    "        Image.fromarray(img)\n",
    "        for img in model.generate_image(\n",
    "            batched_encodings[batch],\n",
    "            batch_size=batch_size,\n",
    "            num_steps=25,\n",
    "            diffusion_noise=noise,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "export_as_gif(\"panda-cat-fino.gif\", images, rubber_band=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IImage(\"panda-cat-fino.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vídeo 5.3 - Criando um caminho circular com ruído"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "# Definindo a seed para garantir consistência no ruído\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Fixando o prompt e a codificação\n",
    "prompt = \"A majestic cat wearing an ornate golden hat, surrounded by floating orbs of light, in a dark illuminist painting, high detail, cinematic lighting, surreal background, elegant fur texture\"\n",
    "encoding = tf.squeeze(model.encode_text(prompt))  # Codificação será sempre a mesma\n",
    "\n",
    "# Parâmetros de caminhada circular\n",
    "walk_steps = 150\n",
    "batch_size = 3\n",
    "batches = walk_steps // batch_size\n",
    "\n",
    "# Gerando ruído com a seed fixa\n",
    "noise = tf.random.normal((512 // 8, 512 // 8, 4), seed=seed)  # Ruído inicial fixo\n",
    "\n",
    "# Gerando ruídos circulares com a mesma seed\n",
    "walk_noise_x = tf.random.normal(noise.shape, dtype=\"float64\", seed=seed)\n",
    "walk_noise_y = tf.random.normal(noise.shape, dtype=\"float64\", seed=seed)\n",
    "\n",
    "# Caminhada circular usando coseno e seno\n",
    "walk_scale_x = tf.cos(tf.linspace(0, 4, walk_steps) * math.pi)\n",
    "walk_scale_y = tf.sin(tf.linspace(0, 4, walk_steps) * math.pi)\n",
    "\n",
    "# Ruído circular aplicado\n",
    "noise_x = tf.tensordot(walk_scale_x, walk_noise_x, axes=0)\n",
    "noise_y = tf.tensordot(walk_scale_y, walk_noise_y, axes=0)\n",
    "noise = tf.add(noise_x, noise_y)\n",
    "\n",
    "# Dividindo o ruído em lotes\n",
    "batched_noise = tf.split(noise, batches)\n",
    "\n",
    "# Gerando imagens sem passar a seed, já que o ruído é manual\n",
    "images = []\n",
    "for batch in range(batches):\n",
    "    images += [\n",
    "        Image.fromarray(img)\n",
    "        for img in model.generate_image(\n",
    "            encoding,\n",
    "            batch_size=batch_size,\n",
    "            num_steps=25,\n",
    "            diffusion_noise=batched_noise[batch],  # Usando apenas o ruído gerado\n",
    "        )\n",
    "    ]\n",
    "\n",
    "# Exportar como GIF com efeito de \"vai e volta\"\n",
    "export_as_gif(\"cat_hat_variation.gif\", images, rubber_band=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf215",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
