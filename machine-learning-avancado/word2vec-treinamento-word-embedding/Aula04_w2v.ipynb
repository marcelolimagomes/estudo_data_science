{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "kDGQFwJTlJ1S"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "\n",
        "spacy.prefer_gpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "colab_type": "code",
        "id": "uCoG4JfZlN_X",
        "outputId": "578b7eea-16bd-40de-b2a5-d3776f7320f4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>date</th>\n",
              "      <th>category</th>\n",
              "      <th>subcategory</th>\n",
              "      <th>link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>39056</th>\n",
              "      <td>Crítica: 'Riso Nervoso' faz rir com situações ...</td>\n",
              "      <td>Apesar da proposta de experimentar um formato ...</td>\n",
              "      <td>2015-12-10</td>\n",
              "      <td>ilustrada</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/ilustrada/2015/10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63062</th>\n",
              "      <td>Com R$ 230 mil para vencedores, novo prêmio li...</td>\n",
              "      <td>Após meses de impasse em relação à realização ...</td>\n",
              "      <td>2015-09-06</td>\n",
              "      <td>ilustrada</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/ilustrada/2015/06...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66851</th>\n",
              "      <td>Líderes devem dar mais poder às máquinas, defe...</td>\n",
              "      <td>Quando a inteligência artificial é má notícia ...</td>\n",
              "      <td>2017-08-19</td>\n",
              "      <td>mercado</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/mercado/2017/08/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54173</th>\n",
              "      <td>Único a perder três finais de Copa América, Ma...</td>\n",
              "      <td>Mascherano passa por uma dor que pode ser desc...</td>\n",
              "      <td>2015-05-07</td>\n",
              "      <td>esporte</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/esporte/2015/07/1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42090</th>\n",
              "      <td>Professor disparou contra atiradores para prot...</td>\n",
              "      <td>\"Mártir\" e \"cavalheiro\" são alguns dos elogios...</td>\n",
              "      <td>2016-01-20</td>\n",
              "      <td>mundo</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://www1.folha.uol.com.br/mundo/2016/01/173...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  \\\n",
              "39056  Crítica: 'Riso Nervoso' faz rir com situações ...   \n",
              "63062  Com R$ 230 mil para vencedores, novo prêmio li...   \n",
              "66851  Líderes devem dar mais poder às máquinas, defe...   \n",
              "54173  Único a perder três finais de Copa América, Ma...   \n",
              "42090  Professor disparou contra atiradores para prot...   \n",
              "\n",
              "                                                    text        date  \\\n",
              "39056  Apesar da proposta de experimentar um formato ...  2015-12-10   \n",
              "63062  Após meses de impasse em relação à realização ...  2015-09-06   \n",
              "66851  Quando a inteligência artificial é má notícia ...  2017-08-19   \n",
              "54173  Mascherano passa por uma dor que pode ser desc...  2015-05-07   \n",
              "42090  \"Mártir\" e \"cavalheiro\" são alguns dos elogios...  2016-01-20   \n",
              "\n",
              "        category subcategory  \\\n",
              "39056  ilustrada         NaN   \n",
              "63062  ilustrada         NaN   \n",
              "66851    mercado         NaN   \n",
              "54173    esporte         NaN   \n",
              "42090      mundo         NaN   \n",
              "\n",
              "                                                    link  \n",
              "39056  http://www1.folha.uol.com.br/ilustrada/2015/10...  \n",
              "63062  http://www1.folha.uol.com.br/ilustrada/2015/06...  \n",
              "66851  http://www1.folha.uol.com.br/mercado/2017/08/1...  \n",
              "54173  http://www1.folha.uol.com.br/esporte/2015/07/1...  \n",
              "42090  http://www1.folha.uol.com.br/mundo/2016/01/173...  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dados_treino = pd.read_csv(\"../introducao-word-embedding/treino.csv\")\n",
        "dados_treino.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "colab_type": "code",
        "id": "0wkJA2A9l3Ap",
        "outputId": "35dcca62-352f-4fae-cd4b-4b853f296394"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pt-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.7.0/pt_core_news_sm-3.7.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from pt-core-news-sm==3.7.0) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.7)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.6)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.2.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.9.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (5.2.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.5.3)\n",
            "Requirement already satisfied: jinja2 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (69.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.14.6)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/marcelo/miniconda3/envs/rapids-24.04/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "#Rodas apenas uma vez\n",
        "!python -m spacy download pt_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4YO1i6fKnHQ1"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"pt_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YPwe50jqmRJk"
      },
      "outputs": [],
      "source": [
        "texto = \"Rio de Janeiro é uma cidade maravilhosa\"\n",
        "doc = nlp(texto)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "10H49z91o9wl",
        "outputId": "32d63ce8-9a7b-4dad-b212-1bd704103d17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Rio de Janeiro é uma cidade maravilhosa"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "doc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "Cfd0v1-Ws4-2",
        "outputId": "6cef1286-225f-4d7c-d86c-9269f8389235"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "spacy.tokens.token.Token"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(doc[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "fkVyn-QZieV1"
      },
      "outputs": [],
      "source": [
        "textos_para_tratamento = (titulos.lower() for titulos in dados_treino[\"title\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "YtSkNlcaiW2w"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Rio Janeiro cidade maravilhosa'"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def trata_textos(doc):\n",
        "    tokens_validos = []\n",
        "    for token in doc:\n",
        "        e_valido = not token.is_stop and token.is_alpha\n",
        "        if e_valido:\n",
        "            tokens_validos.append(token.text)\n",
        "\n",
        "    if len(tokens_validos) > 2:\n",
        "        return  \" \".join(tokens_validos)\n",
        "\n",
        "texto = \"Rio de Janeiro 1231231 ***** @#$ é uma cidade maravilhosa!\"\n",
        "doc = nlp(texto)\n",
        "trata_textos(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "VUgzPI_7lWAO",
        "outputId": "e84fa86a-0311-4442-baa2-975c73710a12"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Rio Janeiro cidade maravilhosa'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texto = \"Rio de Janeiro 1231231 ***** @#$ é uma cidade maravilhosa!\"\n",
        "doc = nlp(texto)\n",
        "trata_textos(doc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "mF7le_-ziJSI",
        "outputId": "10c8c20d-0ad2-439c-af8b-b94d694ecc90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.37393805583318074\n"
          ]
        }
      ],
      "source": [
        "from time import time\n",
        "\n",
        "t0 = time()\n",
        "textos_tratados = [trata_textos(doc) for doc in nlp.pipe(textos_para_tratamento,\n",
        "                                                        batch_size = 1000, \n",
        "                                                        #n_process = -1\n",
        "                                                        )]\n",
        "\n",
        "tf = time() - t0\n",
        "\n",
        "print(tf/60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "colab_type": "code",
        "id": "XWnZ5g_tsp3v",
        "outputId": "cec379bd-6715-414b-d185-459dca02227b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>titulo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>polêmica marine le pen abomina negacionistas h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>macron le pen turno frança revés siglas tradic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>apesar larga vitória legislativas macron terá ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>governo antecipa balanço alckmin anuncia queda...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>queda maio atividade econômica sobe junho bc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              titulo\n",
              "0  polêmica marine le pen abomina negacionistas h...\n",
              "1  macron le pen turno frança revés siglas tradic...\n",
              "2  apesar larga vitória legislativas macron terá ...\n",
              "3  governo antecipa balanço alckmin anuncia queda...\n",
              "4       queda maio atividade econômica sobe junho bc"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "titulos_tratados = pd.DataFrame({\"titulo\": textos_tratados})\n",
        "titulos_tratados.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "2ig6PjO_l5ED"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "w2v_modelo = Word2Vec(sg = 0,\n",
        "                      window = 2,\n",
        "                      vector_size = 300,\n",
        "                      min_count = 5,\n",
        "                      alpha = 0.03,\n",
        "                      min_alpha = 0.007)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "Cf_nt4YfrT8U",
        "outputId": "cc07e543-1485-4d51-ec7e-bcbdd24c515a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<gensim.models.word2vec.Word2Vec at 0x7a912a254bd0>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "colab_type": "code",
        "id": "y07x7J0Y1ubP",
        "outputId": "1bde9a2a-ca0b-4794-b540-77a9e9fe53af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "90000\n",
            "84466\n"
          ]
        }
      ],
      "source": [
        "print(len(titulos_tratados))\n",
        "titulos_tratados = titulos_tratados.dropna().drop_duplicates()\n",
        "print(len(titulos_tratados))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "BtwjbDVH1OWt"
      },
      "outputs": [],
      "source": [
        "lista_lista_tokens = [titulo.split(\" \") for titulo in titulos_tratados.titulo]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "colab_type": "code",
        "id": "TGTR359Q25oP",
        "outputId": "ada7b6e9-90d9-449a-88c9-472fb69e19b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-06 16:32:28,533 : - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.03>', 'datetime': '2024-06-06T16:32:28.533381', 'gensim': '4.3.0', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]', 'platform': 'Linux-6.8.0-35-generic-x86_64-with-glibc2.39', 'event': 'created'}\n",
            "2024-06-06 16:32:28,533 : - collecting all words and their counts\n",
            "2024-06-06 16:32:28,534 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2024-06-06 16:32:28,537 : - PROGRESS: at sentence #5000, processed 31930 words, keeping 10193 word types\n",
            "2024-06-06 16:32:28,540 : - PROGRESS: at sentence #10000, processed 63848 words, keeping 14989 word types\n",
            "2024-06-06 16:32:28,544 : - PROGRESS: at sentence #15000, processed 95753 words, keeping 18279 word types\n",
            "2024-06-06 16:32:28,547 : - PROGRESS: at sentence #20000, processed 127689 words, keeping 21033 word types\n",
            "2024-06-06 16:32:28,551 : - PROGRESS: at sentence #25000, processed 159589 words, keeping 23491 word types\n",
            "2024-06-06 16:32:28,554 : - PROGRESS: at sentence #30000, processed 191554 words, keeping 25494 word types\n",
            "2024-06-06 16:32:28,558 : - PROGRESS: at sentence #35000, processed 223412 words, keeping 27330 word types\n",
            "2024-06-06 16:32:28,562 : - PROGRESS: at sentence #40000, processed 255282 words, keeping 29053 word types\n",
            "2024-06-06 16:32:28,565 : - PROGRESS: at sentence #45000, processed 287297 words, keeping 30606 word types\n",
            "2024-06-06 16:32:28,569 : - PROGRESS: at sentence #50000, processed 319258 words, keeping 31964 word types\n",
            "2024-06-06 16:32:28,573 : - PROGRESS: at sentence #55000, processed 351437 words, keeping 33270 word types\n",
            "2024-06-06 16:32:28,580 : - PROGRESS: at sentence #60000, processed 383579 words, keeping 34520 word types\n",
            "2024-06-06 16:32:28,585 : - PROGRESS: at sentence #65000, processed 415565 words, keeping 35643 word types\n",
            "2024-06-06 16:32:28,591 : - PROGRESS: at sentence #70000, processed 447646 words, keeping 36719 word types\n",
            "2024-06-06 16:32:28,598 : - PROGRESS: at sentence #75000, processed 479568 words, keeping 37802 word types\n",
            "2024-06-06 16:32:28,606 : - PROGRESS: at sentence #80000, processed 511645 words, keeping 38814 word types\n",
            "2024-06-06 16:32:28,611 : - collected 39693 word types from a corpus of 540242 raw words and 84466 sentences\n",
            "2024-06-06 16:32:28,612 : - Creating a fresh vocabulary\n",
            "2024-06-06 16:32:28,630 : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 12924 unique words (32.56% of original 39693, drops 26769)', 'datetime': '2024-06-06T16:32:28.630097', 'gensim': '4.3.0', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]', 'platform': 'Linux-6.8.0-35-generic-x86_64-with-glibc2.39', 'event': 'prepare_vocab'}\n",
            "2024-06-06 16:32:28,630 : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 495223 word corpus (91.67% of original 540242, drops 45019)', 'datetime': '2024-06-06T16:32:28.630520', 'gensim': '4.3.0', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]', 'platform': 'Linux-6.8.0-35-generic-x86_64-with-glibc2.39', 'event': 'prepare_vocab'}\n",
            "2024-06-06 16:32:28,652 : - deleting the raw counts dictionary of 39693 items\n",
            "2024-06-06 16:32:28,653 : - sample=0.001 downsamples 8 most-common words\n",
            "2024-06-06 16:32:28,653 : - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 486147.7552334345 word corpus (98.2%% of prior 495223)', 'datetime': '2024-06-06T16:32:28.653954', 'gensim': '4.3.0', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]', 'platform': 'Linux-6.8.0-35-generic-x86_64-with-glibc2.39', 'event': 'prepare_vocab'}\n",
            "2024-06-06 16:32:28,691 : - estimated required memory for 12924 words and 300 dimensions: 37479600 bytes\n",
            "2024-06-06 16:32:28,691 : - resetting layer weights\n",
            "2024-06-06 16:32:28,700 : - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-06-06T16:32:28.700845', 'gensim': '4.3.0', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]', 'platform': 'Linux-6.8.0-35-generic-x86_64-with-glibc2.39', 'event': 'build_vocab'}\n"
          ]
        }
      ],
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format=\"%(asctime)s : - %(message)s\", level = logging.INFO)\n",
        "\n",
        "w2v_modelo = Word2Vec(sg = 0,\n",
        "                      window = 2,\n",
        "                      vector_size = 300,\n",
        "                      min_count = 5,\n",
        "                      alpha = 0.03,\n",
        "                      min_alpha = 0.007)\n",
        "\n",
        "w2v_modelo.build_vocab(lista_lista_tokens, progress_per=5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "o6Vto_OUkj2j",
        "outputId": "c40e415a-eff0-4ed8-9549-c76cac349dfd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_adapt_by_suffix',\n",
              " '_check_corpus_sanity',\n",
              " '_check_training_sanity',\n",
              " '_clear_post_train',\n",
              " '_do_train_epoch',\n",
              " '_do_train_job',\n",
              " '_get_next_alpha',\n",
              " '_get_thread_working_mem',\n",
              " '_job_producer',\n",
              " '_load_specials',\n",
              " '_log_epoch_end',\n",
              " '_log_epoch_progress',\n",
              " '_log_progress',\n",
              " '_log_train_end',\n",
              " '_raw_word_count',\n",
              " '_save_specials',\n",
              " '_scan_vocab',\n",
              " '_smart_save',\n",
              " '_train_epoch',\n",
              " '_train_epoch_corpusfile',\n",
              " '_worker_loop',\n",
              " '_worker_loop_corpusfile',\n",
              " 'add_lifecycle_event',\n",
              " 'add_null_word',\n",
              " 'alpha',\n",
              " 'batch_words',\n",
              " 'build_vocab',\n",
              " 'build_vocab_from_freq',\n",
              " 'cbow_mean',\n",
              " 'comment',\n",
              " 'compute_loss',\n",
              " 'corpus_count',\n",
              " 'corpus_total_words',\n",
              " 'create_binary_tree',\n",
              " 'cum_table',\n",
              " 'effective_min_count',\n",
              " 'epochs',\n",
              " 'estimate_memory',\n",
              " 'get_latest_training_loss',\n",
              " 'hashfxn',\n",
              " 'hs',\n",
              " 'init_sims',\n",
              " 'init_weights',\n",
              " 'layer1_size',\n",
              " 'lifecycle_events',\n",
              " 'load',\n",
              " 'make_cum_table',\n",
              " 'max_final_vocab',\n",
              " 'max_vocab_size',\n",
              " 'min_alpha',\n",
              " 'min_alpha_yet_reached',\n",
              " 'min_count',\n",
              " 'negative',\n",
              " 'ns_exponent',\n",
              " 'null_word',\n",
              " 'predict_output_word',\n",
              " 'prepare_vocab',\n",
              " 'prepare_weights',\n",
              " 'random',\n",
              " 'raw_vocab',\n",
              " 'reset_from',\n",
              " 'running_training_loss',\n",
              " 'sample',\n",
              " 'save',\n",
              " 'scan_vocab',\n",
              " 'score',\n",
              " 'seed',\n",
              " 'seeded_vector',\n",
              " 'sg',\n",
              " 'shrink_windows',\n",
              " 'sorted_vocab',\n",
              " 'syn1neg',\n",
              " 'total_train_time',\n",
              " 'train',\n",
              " 'train_count',\n",
              " 'update_weights',\n",
              " 'vector_size',\n",
              " 'window',\n",
              " 'workers',\n",
              " 'wv']"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(w2v_modelo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "UQV7LrLFlCQz",
        "outputId": "87c310b1-0828-4e1b-d6eb-e44febdf5548"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "84466"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_modelo.corpus_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "GkZDUKtMkv3e",
        "outputId": "70223207-9308-4c46-c705-f9c2ef3d6453"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-06 16:32:28,711 : - Word2Vec lifecycle event {'msg': 'training model with 3 workers on 12924 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=2 shrink_windows=True', 'datetime': '2024-06-06T16:32:28.711682', 'gensim': '4.3.0', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]', 'platform': 'Linux-6.8.0-35-generic-x86_64-with-glibc2.39', 'event': 'train'}\n",
            "2024-06-06 16:32:28,935 : - EPOCH 0: training on 540242 raw words (486037 effective words) took 0.2s, 2204221 effective words/s\n",
            "2024-06-06 16:32:29,151 : - EPOCH 1: training on 540242 raw words (486138 effective words) took 0.2s, 2301347 effective words/s\n",
            "2024-06-06 16:32:29,365 : - EPOCH 2: training on 540242 raw words (486165 effective words) took 0.2s, 2311997 effective words/s\n",
            "2024-06-06 16:32:29,577 : - EPOCH 3: training on 540242 raw words (486203 effective words) took 0.2s, 2328941 effective words/s\n",
            "2024-06-06 16:32:29,791 : - EPOCH 4: training on 540242 raw words (486071 effective words) took 0.2s, 2312018 effective words/s\n",
            "2024-06-06 16:32:30,004 : - EPOCH 5: training on 540242 raw words (486062 effective words) took 0.2s, 2316952 effective words/s\n",
            "2024-06-06 16:32:30,221 : - EPOCH 6: training on 540242 raw words (486183 effective words) took 0.2s, 2281230 effective words/s\n",
            "2024-06-06 16:32:30,434 : - EPOCH 7: training on 540242 raw words (486219 effective words) took 0.2s, 2321053 effective words/s\n",
            "2024-06-06 16:32:30,645 : - EPOCH 8: training on 540242 raw words (486084 effective words) took 0.2s, 2342013 effective words/s\n",
            "2024-06-06 16:32:30,855 : - EPOCH 9: training on 540242 raw words (486084 effective words) took 0.2s, 2360188 effective words/s\n",
            "2024-06-06 16:32:31,069 : - EPOCH 10: training on 540242 raw words (486259 effective words) took 0.2s, 2308431 effective words/s\n",
            "2024-06-06 16:32:31,280 : - EPOCH 11: training on 540242 raw words (486216 effective words) took 0.2s, 2339627 effective words/s\n",
            "2024-06-06 16:32:31,493 : - EPOCH 12: training on 540242 raw words (486178 effective words) took 0.2s, 2332929 effective words/s\n",
            "2024-06-06 16:32:31,701 : - EPOCH 13: training on 540242 raw words (486094 effective words) took 0.2s, 2366803 effective words/s\n",
            "2024-06-06 16:32:31,911 : - EPOCH 14: training on 540242 raw words (486012 effective words) took 0.2s, 2356504 effective words/s\n",
            "2024-06-06 16:32:32,124 : - EPOCH 15: training on 540242 raw words (486208 effective words) took 0.2s, 2321766 effective words/s\n",
            "2024-06-06 16:32:32,334 : - EPOCH 16: training on 540242 raw words (486162 effective words) took 0.2s, 2359946 effective words/s\n",
            "2024-06-06 16:32:32,542 : - EPOCH 17: training on 540242 raw words (486205 effective words) took 0.2s, 2380550 effective words/s\n",
            "2024-06-06 16:32:32,750 : - EPOCH 18: training on 540242 raw words (486040 effective words) took 0.2s, 2371370 effective words/s\n",
            "2024-06-06 16:32:32,957 : - EPOCH 19: training on 540242 raw words (486115 effective words) took 0.2s, 2387165 effective words/s\n",
            "2024-06-06 16:32:33,167 : - EPOCH 20: training on 540242 raw words (486051 effective words) took 0.2s, 2357407 effective words/s\n",
            "2024-06-06 16:32:33,376 : - EPOCH 21: training on 540242 raw words (486177 effective words) took 0.2s, 2364890 effective words/s\n",
            "2024-06-06 16:32:33,585 : - EPOCH 22: training on 540242 raw words (486316 effective words) took 0.2s, 2366156 effective words/s\n",
            "2024-06-06 16:32:33,814 : - EPOCH 23: training on 540242 raw words (486269 effective words) took 0.2s, 2159360 effective words/s\n",
            "2024-06-06 16:32:34,032 : - EPOCH 24: training on 540242 raw words (486045 effective words) took 0.2s, 2268574 effective words/s\n",
            "2024-06-06 16:32:34,250 : - EPOCH 25: training on 540242 raw words (486176 effective words) took 0.2s, 2262964 effective words/s\n",
            "2024-06-06 16:32:34,485 : - EPOCH 26: training on 540242 raw words (486141 effective words) took 0.2s, 2100911 effective words/s\n",
            "2024-06-06 16:32:34,704 : - EPOCH 27: training on 540242 raw words (486165 effective words) took 0.2s, 2261033 effective words/s\n",
            "2024-06-06 16:32:34,911 : - EPOCH 28: training on 540242 raw words (486015 effective words) took 0.2s, 2382361 effective words/s\n",
            "2024-06-06 16:32:35,127 : - EPOCH 29: training on 540242 raw words (486119 effective words) took 0.2s, 2296711 effective words/s\n",
            "2024-06-06 16:32:35,127 : - Word2Vec lifecycle event {'msg': 'training on 16207260 raw words (14584209 effective words) took 6.4s, 2273288 effective words/s', 'datetime': '2024-06-06T16:32:35.127549', 'gensim': '4.3.0', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]', 'platform': 'Linux-6.8.0-35-generic-x86_64-with-glibc2.39', 'event': 'train'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(14584209, 16207260)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_modelo.train(lista_lista_tokens, \n",
        "                 total_examples=w2v_modelo.corpus_count,\n",
        "                 epochs = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "colab_type": "code",
        "id": "hpHn6jjjlbu_",
        "outputId": "e74a55d5-f5fe-4ad8-c61d-b212183d987c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('apple', 0.5853783488273621),\n",
              " ('facebook', 0.5384712219238281),\n",
              " ('airbnb', 0.48048362135887146),\n",
              " ('waze', 0.46768882870674133),\n",
              " ('uber', 0.45991137623786926),\n",
              " ('amazon', 0.4587847888469696),\n",
              " ('yahoo', 0.4543995261192322),\n",
              " ('reputação', 0.44935259222984314),\n",
              " ('promotora', 0.4446452856063843),\n",
              " ('tesla', 0.4417654573917389)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_modelo.wv.most_similar(\"google\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "colab_type": "code",
        "id": "Mp4MMuJcmLer",
        "outputId": "6a4d376f-8a13-4ca6-dc14-10a1b87074cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('unilever', 0.5704851150512695),\n",
              " ('amazon', 0.5526418685913086),\n",
              " ('sky', 0.5364922881126404),\n",
              " ('tesla', 0.49938392639160156),\n",
              " ('buffett', 0.4972078800201416),\n",
              " ('braskem', 0.4934007227420807),\n",
              " ('walmart', 0.48912063241004944),\n",
              " ('syngenta', 0.48294442892074585),\n",
              " ('bingo', 0.4799862504005432),\n",
              " ('sony', 0.4760758876800537)]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_modelo.wv.most_similar(\"microsoft\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "colab_type": "code",
        "id": "Gb8pApHjmfkf",
        "outputId": "3345cb83-fa96-4729-8ce4-3ba6f1c24f47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('bayern', 0.5606571435928345),\n",
              " ('barça', 0.556068480014801),\n",
              " ('madrid', 0.5485405921936035),\n",
              " ('united', 0.5452345013618469),\n",
              " ('lazio', 0.5346264243125916),\n",
              " ('juventus', 0.5250296592712402),\n",
              " ('munique', 0.5249300599098206),\n",
              " ('chelsea', 0.5179049968719482),\n",
              " ('psg', 0.5076916813850403),\n",
              " ('liverpool', 0.49374499917030334)]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_modelo.wv.most_similar(\"barcelona\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "colab_type": "code",
        "id": "tbiumQBim1ur",
        "outputId": "e6ff57e6-fede-4fd6-acb8-b42fcdf159cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('suárez', 0.5900891423225403),\n",
              " ('chuteiras', 0.5271071791648865),\n",
              " ('cristiano', 0.5209771990776062),\n",
              " ('cavani', 0.5183922052383423),\n",
              " ('neymar', 0.5141710638999939),\n",
              " ('tevez', 0.5139928460121155),\n",
              " ('enrique', 0.4907070994377136),\n",
              " ('benzema', 0.48883572220802307),\n",
              " ('barça', 0.4762296676635742),\n",
              " ('psg', 0.4673621952533722)]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_modelo.wv.most_similar(\"messi\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "colab_type": "code",
        "id": "adwP-TKvm7pE",
        "outputId": "2c9f8580-a97c-4285-dc95-1a64bdaf1a04"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('volks', 0.6724461317062378),\n",
              " ('embraer', 0.6514822840690613),\n",
              " ('chrysler', 0.6378532648086548),\n",
              " ('honda', 0.6226741075515747),\n",
              " ('braskem', 0.6017970442771912),\n",
              " ('csn', 0.5902283191680908),\n",
              " ('toyota', 0.5754856467247009),\n",
              " ('tesla', 0.5674526691436768),\n",
              " ('fiat', 0.5630203485488892),\n",
              " ('metalúrgicos', 0.5601111054420471)]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_modelo.wv.most_similar(\"gm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "lAQ--B5Xu1Vu",
        "outputId": "fe41f513-656e-47b1-b5fc-cc99c7dbe4d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-06 16:32:35,197 : - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=300, alpha=0.03>', 'datetime': '2024-06-06T16:32:35.197448', 'gensim': '4.3.0', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]', 'platform': 'Linux-6.8.0-35-generic-x86_64-with-glibc2.39', 'event': 'created'}\n",
            "2024-06-06 16:32:35,200 : - collecting all words and their counts\n",
            "2024-06-06 16:32:35,201 : - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "2024-06-06 16:32:35,210 : - PROGRESS: at sentence #5000, processed 31930 words, keeping 10193 word types\n",
            "2024-06-06 16:32:35,218 : - PROGRESS: at sentence #10000, processed 63848 words, keeping 14989 word types\n",
            "2024-06-06 16:32:35,225 : - PROGRESS: at sentence #15000, processed 95753 words, keeping 18279 word types\n",
            "2024-06-06 16:32:35,237 : - PROGRESS: at sentence #20000, processed 127689 words, keeping 21033 word types\n",
            "2024-06-06 16:32:35,245 : - PROGRESS: at sentence #25000, processed 159589 words, keeping 23491 word types\n",
            "2024-06-06 16:32:35,251 : - PROGRESS: at sentence #30000, processed 191554 words, keeping 25494 word types\n",
            "2024-06-06 16:32:35,255 : - PROGRESS: at sentence #35000, processed 223412 words, keeping 27330 word types\n",
            "2024-06-06 16:32:35,260 : - PROGRESS: at sentence #40000, processed 255282 words, keeping 29053 word types\n",
            "2024-06-06 16:32:35,265 : - PROGRESS: at sentence #45000, processed 287297 words, keeping 30606 word types\n",
            "2024-06-06 16:32:35,271 : - PROGRESS: at sentence #50000, processed 319258 words, keeping 31964 word types\n",
            "2024-06-06 16:32:35,276 : - PROGRESS: at sentence #55000, processed 351437 words, keeping 33270 word types\n",
            "2024-06-06 16:32:35,281 : - PROGRESS: at sentence #60000, processed 383579 words, keeping 34520 word types\n",
            "2024-06-06 16:32:35,286 : - PROGRESS: at sentence #65000, processed 415565 words, keeping 35643 word types\n",
            "2024-06-06 16:32:35,291 : - PROGRESS: at sentence #70000, processed 447646 words, keeping 36719 word types\n",
            "2024-06-06 16:32:35,295 : - PROGRESS: at sentence #75000, processed 479568 words, keeping 37802 word types\n",
            "2024-06-06 16:32:35,307 : - PROGRESS: at sentence #80000, processed 511645 words, keeping 38814 word types\n",
            "2024-06-06 16:32:35,317 : - collected 39693 word types from a corpus of 540242 raw words and 84466 sentences\n",
            "2024-06-06 16:32:35,318 : - Creating a fresh vocabulary\n",
            "2024-06-06 16:32:35,341 : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 retains 12924 unique words (32.56% of original 39693, drops 26769)', 'datetime': '2024-06-06T16:32:35.341460', 'gensim': '4.3.0', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]', 'platform': 'Linux-6.8.0-35-generic-x86_64-with-glibc2.39', 'event': 'prepare_vocab'}\n",
            "2024-06-06 16:32:35,341 : - Word2Vec lifecycle event {'msg': 'effective_min_count=5 leaves 495223 word corpus (91.67% of original 540242, drops 45019)', 'datetime': '2024-06-06T16:32:35.341983', 'gensim': '4.3.0', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]', 'platform': 'Linux-6.8.0-35-generic-x86_64-with-glibc2.39', 'event': 'prepare_vocab'}\n",
            "2024-06-06 16:32:35,363 : - deleting the raw counts dictionary of 39693 items\n",
            "2024-06-06 16:32:35,363 : - sample=0.001 downsamples 8 most-common words\n",
            "2024-06-06 16:32:35,363 : - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 486147.7552334345 word corpus (98.2%% of prior 495223)', 'datetime': '2024-06-06T16:32:35.363974', 'gensim': '4.3.0', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]', 'platform': 'Linux-6.8.0-35-generic-x86_64-with-glibc2.39', 'event': 'prepare_vocab'}\n",
            "2024-06-06 16:32:35,399 : - estimated required memory for 12924 words and 300 dimensions: 37479600 bytes\n",
            "2024-06-06 16:32:35,399 : - resetting layer weights\n",
            "2024-06-06 16:32:35,406 : - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-06-06T16:32:35.406478', 'gensim': '4.3.0', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]', 'platform': 'Linux-6.8.0-35-generic-x86_64-with-glibc2.39', 'event': 'build_vocab'}\n",
            "2024-06-06 16:32:35,406 : - Word2Vec lifecycle event {'msg': 'training model with 3 workers on 12924 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2024-06-06T16:32:35.406867', 'gensim': '4.3.0', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]', 'platform': 'Linux-6.8.0-35-generic-x86_64-with-glibc2.39', 'event': 'train'}\n",
            "2024-06-06 16:32:35,987 : - EPOCH 0: training on 540242 raw words (486058 effective words) took 0.6s, 841784 effective words/s\n",
            "2024-06-06 16:32:36,554 : - EPOCH 1: training on 540242 raw words (486094 effective words) took 0.6s, 862855 effective words/s\n",
            "2024-06-06 16:32:37,136 : - EPOCH 2: training on 540242 raw words (486158 effective words) took 0.6s, 841045 effective words/s\n",
            "2024-06-06 16:32:37,704 : - EPOCH 3: training on 540242 raw words (486255 effective words) took 0.6s, 861757 effective words/s\n",
            "2024-06-06 16:32:38,267 : - EPOCH 4: training on 540242 raw words (486208 effective words) took 0.6s, 868458 effective words/s\n",
            "2024-06-06 16:32:38,833 : - EPOCH 5: training on 540242 raw words (486016 effective words) took 0.6s, 864693 effective words/s\n",
            "2024-06-06 16:32:39,398 : - EPOCH 6: training on 540242 raw words (486163 effective words) took 0.6s, 865943 effective words/s\n",
            "2024-06-06 16:32:40,003 : - EPOCH 7: training on 540242 raw words (486117 effective words) took 0.6s, 809173 effective words/s\n",
            "2024-06-06 16:32:40,564 : - EPOCH 8: training on 540242 raw words (486109 effective words) took 0.6s, 871912 effective words/s\n",
            "2024-06-06 16:32:41,132 : - EPOCH 9: training on 540242 raw words (486092 effective words) took 0.6s, 860481 effective words/s\n",
            "2024-06-06 16:32:41,709 : - EPOCH 10: training on 540242 raw words (486145 effective words) took 0.6s, 848911 effective words/s\n",
            "2024-06-06 16:32:42,281 : - EPOCH 11: training on 540242 raw words (486229 effective words) took 0.6s, 855449 effective words/s\n",
            "2024-06-06 16:32:42,848 : - EPOCH 12: training on 540242 raw words (486106 effective words) took 0.6s, 862274 effective words/s\n",
            "2024-06-06 16:32:43,409 : - EPOCH 13: training on 540242 raw words (486226 effective words) took 0.6s, 873264 effective words/s\n",
            "2024-06-06 16:32:43,977 : - EPOCH 14: training on 540242 raw words (486059 effective words) took 0.6s, 860768 effective words/s\n",
            "2024-06-06 16:32:44,546 : - EPOCH 15: training on 540242 raw words (486239 effective words) took 0.6s, 860212 effective words/s\n",
            "2024-06-06 16:32:45,115 : - EPOCH 16: training on 540242 raw words (486138 effective words) took 0.6s, 859913 effective words/s\n",
            "2024-06-06 16:32:45,691 : - EPOCH 17: training on 540242 raw words (486207 effective words) took 0.6s, 849304 effective words/s\n",
            "2024-06-06 16:32:46,257 : - EPOCH 18: training on 540242 raw words (486275 effective words) took 0.6s, 863844 effective words/s\n",
            "2024-06-06 16:32:46,817 : - EPOCH 19: training on 540242 raw words (486118 effective words) took 0.6s, 874585 effective words/s\n",
            "2024-06-06 16:32:47,372 : - EPOCH 20: training on 540242 raw words (486242 effective words) took 0.6s, 881813 effective words/s\n",
            "2024-06-06 16:32:47,927 : - EPOCH 21: training on 540242 raw words (486204 effective words) took 0.6s, 881818 effective words/s\n",
            "2024-06-06 16:32:48,484 : - EPOCH 22: training on 540242 raw words (486184 effective words) took 0.6s, 877867 effective words/s\n",
            "2024-06-06 16:32:49,043 : - EPOCH 23: training on 540242 raw words (486100 effective words) took 0.6s, 875314 effective words/s\n",
            "2024-06-06 16:32:49,607 : - EPOCH 24: training on 540242 raw words (486094 effective words) took 0.6s, 867115 effective words/s\n",
            "2024-06-06 16:32:50,171 : - EPOCH 25: training on 540242 raw words (486105 effective words) took 0.6s, 868147 effective words/s\n",
            "2024-06-06 16:32:50,724 : - EPOCH 26: training on 540242 raw words (486209 effective words) took 0.5s, 884992 effective words/s\n",
            "2024-06-06 16:32:51,274 : - EPOCH 27: training on 540242 raw words (486067 effective words) took 0.5s, 890409 effective words/s\n",
            "2024-06-06 16:32:51,825 : - EPOCH 28: training on 540242 raw words (486168 effective words) took 0.5s, 888155 effective words/s\n",
            "2024-06-06 16:32:52,375 : - EPOCH 29: training on 540242 raw words (486127 effective words) took 0.5s, 888871 effective words/s\n",
            "2024-06-06 16:32:52,376 : - Word2Vec lifecycle event {'msg': 'training on 16207260 raw words (14584512 effective words) took 17.0s, 859474 effective words/s', 'datetime': '2024-06-06T16:32:52.376183', 'gensim': '4.3.0', 'python': '3.11.9 | packaged by conda-forge | (main, Apr 19 2024, 18:36:13) [GCC 12.3.0]', 'platform': 'Linux-6.8.0-35-generic-x86_64-with-glibc2.39', 'event': 'train'}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(14584512, 16207260)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Treinamento do modelo Skip-Gram\n",
        "w2v_modelo_sg = Word2Vec(sg = 1,\n",
        "                      window = 5,\n",
        "                      vector_size = 300,\n",
        "                      min_count = 5,\n",
        "                      alpha = 0.03,\n",
        "                      min_alpha = 0.007)\n",
        "\n",
        "w2v_modelo_sg.build_vocab(lista_lista_tokens, progress_per=5000)\n",
        "\n",
        "w2v_modelo_sg.train(lista_lista_tokens, \n",
        "                 total_examples=w2v_modelo_sg.corpus_count,\n",
        "                 epochs = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "colab_type": "code",
        "id": "m26eXZjOxQBo",
        "outputId": "1b1da834-4968-4a77-9086-5c36741585bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('reguladores', 0.4501875042915344),\n",
              " ('android', 0.4084903299808502),\n",
              " ('waze', 0.38049954175949097),\n",
              " ('concorda', 0.3795197010040283),\n",
              " ('facebook', 0.3745160698890686),\n",
              " ('buffett', 0.3742385506629944),\n",
              " ('verizon', 0.36863839626312256),\n",
              " ('walmart', 0.36834385991096497),\n",
              " ('toshiba', 0.36084863543510437),\n",
              " ('yahoo', 0.35604071617126465)]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_modelo_sg.wv.most_similar(\"google\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "colab_type": "code",
        "id": "mp37nGkryZDl",
        "outputId": "fa5287c2-8d71-4919-f83c-5148e9ff6478"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('apple', 0.5853783488273621),\n",
              " ('facebook', 0.5384712219238281),\n",
              " ('airbnb', 0.48048362135887146),\n",
              " ('waze', 0.46768882870674133),\n",
              " ('uber', 0.45991137623786926),\n",
              " ('amazon', 0.4587847888469696),\n",
              " ('yahoo', 0.4543995261192322),\n",
              " ('reputação', 0.44935259222984314),\n",
              " ('promotora', 0.4446452856063843),\n",
              " ('tesla', 0.4417654573917389)]"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_modelo.wv.most_similar(\"google\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "colab_type": "code",
        "id": "v7ObTWU2yjor",
        "outputId": "b4a55323-6856-4218-ff6f-d5c9c30034a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('metalúrgicos', 0.592609167098999),\n",
              " ('motors', 0.53378826379776),\n",
              " ('audi', 0.48546361923217773),\n",
              " ('airbags', 0.4805930554866791),\n",
              " ('fiat', 0.4751640558242798),\n",
              " ('bmw', 0.4749111831188202),\n",
              " ('honda', 0.47376903891563416),\n",
              " ('chrysler', 0.4653456509113312),\n",
              " ('airbag', 0.45837751030921936),\n",
              " ('cubatão', 0.4563847780227661)]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_modelo_sg.wv.most_similar(\"gm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "colab_type": "code",
        "id": "Hthy8bAyy8eu",
        "outputId": "b72571f8-8e5a-41ac-d628-11e0ba6ff68a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('volks', 0.6724461317062378),\n",
              " ('embraer', 0.6514822840690613),\n",
              " ('chrysler', 0.6378532648086548),\n",
              " ('honda', 0.6226741075515747),\n",
              " ('braskem', 0.6017970442771912),\n",
              " ('csn', 0.5902283191680908),\n",
              " ('toyota', 0.5754856467247009),\n",
              " ('tesla', 0.5674526691436768),\n",
              " ('fiat', 0.5630203485488892),\n",
              " ('metalúrgicos', 0.5601111054420471)]"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "w2v_modelo.wv.most_similar(\"gm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "colab_type": "code",
        "id": "PVuShjpFzA2g",
        "outputId": "56c20748-dfc6-4ac6-a515-8c792282264c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-06 16:32:52,453 : - storing 12924x300 projection weights into modelo_cbow.txt\n",
            "2024-06-06 16:32:53,374 : - storing 12924x300 projection weights into modelo_skipgram.txt\n"
          ]
        }
      ],
      "source": [
        "w2v_modelo.wv.save_word2vec_format(\"modelo_cbow.txt\", binary=False)\n",
        "w2v_modelo_sg.wv.save_word2vec_format(\"modelo_skipgram.txt\", binary=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Ii643vR80g3K"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-06-06 16:32:54,180 : - storing 12924x300 projection weights into rl_cbow.pkl\n",
            "2024-06-06 16:32:54,206 : - storing 12924x300 projection weights into rl_sg.pkl\n"
          ]
        }
      ],
      "source": [
        "w2v_modelo.wv.save_word2vec_format(\"rl_cbow.pkl\", binary=True)\n",
        "w2v_modelo_sg.wv.save_word2vec_format(\"rl_sg.pkl\", binary=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Aula04_w2v.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
